{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in final dataset\n",
    "df = pd.read_csv('/Users/myokim/Desktop/general_assembly/Projects/Capstone/datasets_clean/final_dataset.csv')\n",
    "\n",
    "df.drop(columns = ['Unnamed: 0', 'imageAltText', 'salePrice', 'valuePrice', 'skuType'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name</th>\n",
       "      <th>category</th>\n",
       "      <th>isLimitedEdition</th>\n",
       "      <th>isNew</th>\n",
       "      <th>isOnlineOnly</th>\n",
       "      <th>isSephoraExclusive</th>\n",
       "      <th>listPrice</th>\n",
       "      <th>skuId</th>\n",
       "      <th>target_x</th>\n",
       "      <th>1 star</th>\n",
       "      <th>2 stars</th>\n",
       "      <th>3 stars</th>\n",
       "      <th>4 stars</th>\n",
       "      <th>5 stars</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>review_count_y</th>\n",
       "      <th>total_ratings</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FENTY BEAUTY by Rihanna</td>\n",
       "      <td>foundation-makeup</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2268274</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.860733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAT McGRATH LABS</td>\n",
       "      <td>foundation-makeup</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2257111</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>880.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.767496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FENTY BEAUTY by Rihanna</td>\n",
       "      <td>foundation-makeup</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2164671</td>\n",
       "      <td>0</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>1324.0</td>\n",
       "      <td>2149.0</td>\n",
       "      <td>8379.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>14270.0</td>\n",
       "      <td>14270.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MILK MAKEUP</td>\n",
       "      <td>foundation-makeup</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2242105</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>363.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Estée Lauder</td>\n",
       "      <td>foundation-makeup</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2112167</td>\n",
       "      <td>0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>3758.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5365.0</td>\n",
       "      <td>5365.0</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.782008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                brand_name           category  isLimitedEdition  isNew  \\\n",
       "0  FENTY BEAUTY by Rihanna  foundation-makeup             False   True   \n",
       "1         PAT McGRATH LABS  foundation-makeup             False   True   \n",
       "2  FENTY BEAUTY by Rihanna  foundation-makeup             False  False   \n",
       "3              MILK MAKEUP  foundation-makeup             False   True   \n",
       "4             Estée Lauder  foundation-makeup             False  False   \n",
       "\n",
       "   isOnlineOnly  isSephoraExclusive  listPrice    skuId  target_x  1 star  \\\n",
       "0          True                True       35.0  2268274         0     0.0   \n",
       "1         False                True       68.0  2257111         0    28.0   \n",
       "2         False                True       35.0  2164671         0  1139.0   \n",
       "3         False                True       36.0  2242105         0     1.0   \n",
       "4         False               False       43.0  2112167         0   213.0   \n",
       "\n",
       "   2 stars  3 stars  4 stars  5 stars  avg_rating  review_count_y  \\\n",
       "0      0.0      0.0      5.0     11.0         4.7            16.0   \n",
       "1     35.0     57.0    212.0    548.0         4.4           880.0   \n",
       "2   1279.0   1324.0   2149.0   8379.0         4.1         14270.0   \n",
       "3     10.0     23.0    115.0    214.0         4.5           363.0   \n",
       "4    258.0    299.0    837.0   3758.0         4.4          5365.0   \n",
       "\n",
       "   total_ratings  compound_score  compound  \n",
       "0           16.0             NaN  0.860733  \n",
       "1          880.0             NaN  0.767496  \n",
       "2        14270.0             NaN  0.616840  \n",
       "3          363.0             NaN  0.775412  \n",
       "4         5365.0        0.012698  0.782008  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand_name               0\n",
       "category                 0\n",
       "isLimitedEdition         0\n",
       "isNew                    0\n",
       "isOnlineOnly             0\n",
       "isSephoraExclusive       0\n",
       "listPrice                0\n",
       "skuId                    0\n",
       "target_x                 0\n",
       "1 star                 900\n",
       "2 stars                900\n",
       "3 stars                900\n",
       "4 stars                900\n",
       "5 stars                900\n",
       "avg_rating             900\n",
       "review_count_y         900\n",
       "total_ratings          900\n",
       "compound_score        1687\n",
       "compound               925\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy features for binary columns\n",
    "df = pd.get_dummies(df, columns = ['isLimitedEdition', 'isNew', 'isOnlineOnly', 'isSephoraExclusive', 'brand_name', 'category'], drop_first = True)\n",
    "\n",
    "\n",
    "\n",
    "df.fillna(0, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'target_x')\n",
    "\n",
    "y = df['target_x']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.954686\n",
       "1    0.045314\n",
       "Name: target_x, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.955247\n",
       "1    0.044753\n",
       "Name: target_x, dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training score for gs: 0.3662032269138345\n",
      "Best parameters: {'C': 0.75, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Test score: 0.9583333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "gs_lr = GridSearchCV(\n",
    "            estimator = lr, \n",
    "            param_grid = {\n",
    "                 'penalty': ['l1','l2'],\n",
    "                 'C': [.25, .5, .75, 1],\n",
    "                 'solver': ['liblinear']},\n",
    "            cv = 5,\n",
    "            scoring = 'precision')\n",
    "\n",
    "gs_lr.fit(X_train, y_train)\n",
    "print(f'Best training score for gs: {gs_lr.best_score_}')\n",
    "print(f'Best parameters: {gs_lr.best_params_}')\n",
    "lr = gs_lr.best_estimator_\n",
    "print(f'Test score: {lr.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_weights = pd.DataFrame(index = X.columns, data = lr.coef_.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brand_name_Black Up</th>\n",
       "      <td>3.539354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_name_GLAMGLOW</th>\n",
       "      <td>3.349824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_name_trèStiQue</th>\n",
       "      <td>3.108530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_name_Wander Beauty</th>\n",
       "      <td>2.435148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_name_MILK MAKEUP</th>\n",
       "      <td>1.777935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0\n",
       "brand_name_Black Up       3.539354\n",
       "brand_name_GLAMGLOW       3.349824\n",
       "brand_name_trèStiQue      3.108530\n",
       "brand_name_Wander Beauty  2.435148\n",
       "brand_name_MILK MAKEUP    1.777935"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_weights[lr_weights[0]>0].sort_values(by = 0,ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category_mascara</th>\n",
       "      <td>-1.783226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isNew_True</th>\n",
       "      <td>-1.400692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound</th>\n",
       "      <td>-0.680398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_name_tarte</th>\n",
       "      <td>-0.566430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_setting-powder-face-powder</th>\n",
       "      <td>-0.549702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            0\n",
       "category_mascara                    -1.783226\n",
       "isNew_True                          -1.400692\n",
       "compound                            -0.680398\n",
       "brand_name_tarte                    -0.566430\n",
       "category_setting-powder-face-powder -0.549702"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_weights[lr_weights[0]<0].sort_values(by = 0,ascending = True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       619\n",
      "           1       0.62      0.17      0.27        29\n",
      "\n",
      "    accuracy                           0.96       648\n",
      "   macro avg       0.79      0.58      0.62       648\n",
      "weighted avg       0.95      0.96      0.95       648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, lr.predict(X_test))\n",
    "\n",
    "cm_df = pd.DataFrame(cm, columns = ['pred full price', 'pred sale'],\n",
    "            index = ['actual full price', 'actual sale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred full price</th>\n",
       "      <th>pred sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual full price</th>\n",
       "      <td>616</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual sale</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pred full price  pred sale\n",
       "actual full price              616          3\n",
       "actual sale                     24          5"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9951534733441034"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specificity \n",
    "(cm_df.iloc[0,0])/(cm_df.iloc[0,1]+cm_df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1724137931034483"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sensitivity \n",
    "(cm_df.iloc[1,1]/(cm_df.iloc[1,0]+cm_df.iloc[1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, \n",
    "                activation='relu', \n",
    "                input_shape=(X_train_sc.shape[1],)))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1942 samples, validate on 648 samples\n",
      "Epoch 1/7\n",
      "1942/1942 [==============================] - 0s 249us/step - loss: 0.5750 - acc: 0.7467 - val_loss: 0.4840 - val_acc: 0.8426\n",
      "Epoch 2/7\n",
      "1942/1942 [==============================] - 0s 26us/step - loss: 0.3798 - acc: 0.9083 - val_loss: 0.3410 - val_acc: 0.9151\n",
      "Epoch 3/7\n",
      "1942/1942 [==============================] - 0s 28us/step - loss: 0.2752 - acc: 0.9459 - val_loss: 0.2623 - val_acc: 0.9429\n",
      "Epoch 4/7\n",
      "1942/1942 [==============================] - 0s 25us/step - loss: 0.2185 - acc: 0.9516 - val_loss: 0.2202 - val_acc: 0.9475\n",
      "Epoch 5/7\n",
      "1942/1942 [==============================] - 0s 28us/step - loss: 0.1852 - acc: 0.9542 - val_loss: 0.1948 - val_acc: 0.9475\n",
      "Epoch 6/7\n",
      "1942/1942 [==============================] - 0s 26us/step - loss: 0.1643 - acc: 0.9557 - val_loss: 0.1790 - val_acc: 0.9506\n",
      "Epoch 7/7\n",
      "1942/1942 [==============================] - 0s 27us/step - loss: 0.1497 - acc: 0.9562 - val_loss: 0.1696 - val_acc: 0.9506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a344e8748>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_sc, y_train, \n",
    "         epochs = 7, \n",
    "         batch_size = 128, \n",
    "         validation_data = (X_test_sc, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1942, 44)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(648,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(model.predict_classes(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing brand name from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in final dataset\n",
    "df_2 = pd.read_csv('/Users/myokim/Desktop/general_assembly/Projects/Capstone/datasets_clean/final_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.drop(columns = ['Unnamed: 0', 'imageAltText', 'salePrice', 'valuePrice', 'brand_name', 'skuType'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy features for binary columns\n",
    "df_2 = pd.get_dummies(df_2, columns = ['isLimitedEdition', 'isNew', 'isOnlineOnly', 'isSephoraExclusive', 'category'], drop_first = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.fillna(0, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_2.drop(columns = 'target_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_2['target_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training score for gs: 0.9546858908341915\n",
      "Best parameters: {'C': 0.25, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Test score: 0.9552469135802469\n"
     ]
    }
   ],
   "source": [
    "lr_2 = LogisticRegression()\n",
    "gs_lr_2 = GridSearchCV(estimator = lr_2, \n",
    "             param_grid = {\n",
    "                 'penalty': ['l1','l2'],\n",
    "                 'C': [.25, .5, .75, 1],\n",
    "                 'solver': ['liblinear']},\n",
    "                    cv = 5)\n",
    "\n",
    "gs_lr_2.fit(X_train, y_train)\n",
    "print(f'Best training score for gs: {gs_lr_2.best_score_}')\n",
    "print(f'Best parameters: {gs_lr_2.best_params_}')\n",
    "lr_2 = gs_lr_2.best_estimator_\n",
    "print(f'Test score: {lr_2.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_weights_2 = pd.DataFrame(index = X.columns, data = lr.coef_.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0006398071045870977"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(lr_weights_2, .99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isLimitedEdition_True</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isSephoraExclusive_True</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "isLimitedEdition_True    0.0\n",
       "isSephoraExclusive_True  0.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_weights_2[lr_weights_2[0]>0.0000009].round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5 stars</th>\n",
       "      <td>-0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_count_y</th>\n",
       "      <td>-0.00064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_ratings</th>\n",
       "      <td>-0.00064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "5 stars        -0.00043\n",
       "review_count_y -0.00064\n",
       "total_ratings  -0.00064"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_weights_2[lr_weights_2[0]<-0.0003].round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lr_2.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1942"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the classes are so unbalanced, try out random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in final dataset\n",
    "df = pd.read_csv('/Users/myokim/Desktop/general_assembly/Projects/Capstone/datasets_clean/final_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Unnamed: 0', 'imageAltText', 'salePrice', 'valuePrice', 'skuType'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy features for binary columns\n",
    "df = pd.get_dummies(df, columns = ['isLimitedEdition', 'isNew', 'isOnlineOnly', 'isSephoraExclusive', 'brand_name', 'category'], drop_first = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'target_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training score for gs: 0.9536560247167868\n",
      "Best parameters: {'class_weight': 'balanced', 'max_depth': None, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Test score: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "gs_rf = GridSearchCV(\n",
    "            estimator = rf, \n",
    "            param_grid = {\n",
    "                'n_estimators': [10,50,100],\n",
    "                'max_depth': [None, 2],\n",
    "                'min_samples_split': [2, 5, 8],\n",
    "                'class_weight':['balanced'],\n",
    "                'max_features': ['auto', 'log2', None]\n",
    "            },\n",
    "            cv = 3)\n",
    "\n",
    "gs_rf.fit(X_train, y_train)\n",
    "print(f'Best training score for gs: {gs_rf.best_score_}')\n",
    "print(f'Best parameters: {gs_rf.best_params_}')\n",
    "rf = gs_lr.best_estimator_\n",
    "print(f'Test score: {rf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5837836332237759"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5837836332237759"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log reg round 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in final dataset\n",
    "df = pd.read_csv('/Users/myokim/Desktop/general_assembly/Projects/Capstone/datasets_clean/final_dataset.csv')\n",
    "\n",
    "df.drop(columns = ['Unnamed: 0', 'imageAltText', 'salePrice', 'valuePrice', 'skuType'], inplace = True)\n",
    "\n",
    "# Create dummy features for binary columns\n",
    "df = pd.get_dummies(df, columns = ['isLimitedEdition', 'isNew', 'isOnlineOnly', 'isSephoraExclusive', 'brand_name', 'category'], drop_first = True)\n",
    "\n",
    "\n",
    "\n",
    "df.fillna(0, inplace= True)\n",
    "\n",
    "X = df.drop(columns = 'target_x')\n",
    "\n",
    "y = df['target_x']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training score for gs: 0.8614830072090628\n",
      "Best parameters: {'C': 0.75, 'class_weight': 'balanced', 'max_iter': 5000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Test score: 0.8842592592592593\n"
     ]
    }
   ],
   "source": [
    "lr_3 = LogisticRegression()\n",
    "gs_lr_3 = GridSearchCV(\n",
    "            estimator = lr_3, \n",
    "            param_grid = {\n",
    "                 'penalty': ['l1','l2'],\n",
    "                 'C': [.75, 1],\n",
    "                 'solver': ['liblinear'],\n",
    "                 'class_weight': ['balanced'],\n",
    "                'max_iter' : [5000]},\n",
    "            cv = 5,\n",
    "            scoring = 'accuracy')\n",
    "\n",
    "gs_lr_3.fit(X_train, y_train)\n",
    "print(f'Best training score for gs: {gs_lr_3.best_score_}')\n",
    "print(f'Best parameters: {gs_lr_3.best_params_}')\n",
    "lr_3 = gs_lr_3.best_estimator_\n",
    "print(f'Test score: {lr_3.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8736839173305108"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, lr_3.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of predicted sale test set: 96\n",
      "Count of predicted sale train set: 337\n",
      "Count of actual sales test set: 29\n"
     ]
    }
   ],
   "source": [
    "print(f'Count of predicted sale test set: {sum(lr_3.predict(X_test))}')\n",
    "\n",
    "print(f'Count of predicted sale train set: {sum(lr_3.predict(X_train))}')\n",
    "\n",
    "print(f'Count of actual sales test set: {sum(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred full price</th>\n",
       "      <th>pred sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual full price</th>\n",
       "      <td>548</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual sale</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pred full price  pred sale\n",
       "actual full price              548         71\n",
       "actual sale                      4         25"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, lr_3.predict(X_test))\n",
    "\n",
    "cm_df = pd.DataFrame(cm, columns = ['pred full price', 'pred sale'],\n",
    "            index = ['actual full price', 'actual sale'])\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8852988691437803"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specificity \n",
    "(cm_df.iloc[0,0])/(cm_df.iloc[0,1]+cm_df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8620689655172413"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sensitivity \n",
    "(cm_df.iloc[1,1]/(cm_df.iloc[1,0]+cm_df.iloc[1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change hyperparameters and using scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in final dataset\n",
    "df = pd.read_csv('/Users/myokim/Desktop/general_assembly/Projects/Capstone/datasets_clean/final_dataset.csv')\n",
    "\n",
    "df.drop(columns = ['Unnamed: 0', 'imageAltText', 'salePrice', 'valuePrice', 'skuType'], inplace = True)\n",
    "\n",
    "# Create dummy features for binary columns\n",
    "df = pd.get_dummies(df, columns = ['isLimitedEdition', 'isNew', 'isOnlineOnly', 'isSephoraExclusive', 'brand_name', 'category'], drop_first = True)\n",
    "\n",
    "\n",
    "\n",
    "df.fillna(0, inplace= True)\n",
    "\n",
    "X = df.drop(columns = 'target_x')\n",
    "\n",
    "y = df['target_x']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify = y, random_state = 42)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training score for gs: 0.8594232749742533\n",
      "Best parameters: {'C': 1, 'class_weight': 'balanced', 'max_iter': 5000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Test score: 0.9552469135802469\n"
     ]
    }
   ],
   "source": [
    "lr_3 = LogisticRegression()\n",
    "gs_lr_3 = GridSearchCV(\n",
    "            estimator = lr_3, \n",
    "            param_grid = {\n",
    "                 'penalty': ['l1','l2'],\n",
    "                 'C': [.75, 1],\n",
    "                 'solver': ['liblinear', 'saga'],\n",
    "                 'class_weight': ['balanced'],\n",
    "                'max_iter' : [5000]},\n",
    "            cv = 5,\n",
    "            scoring = 'accuracy')\n",
    "\n",
    "gs_lr_3.fit(X_train_sc, y_train)\n",
    "print(f'Best training score for gs: {gs_lr_3.best_score_}')\n",
    "print(f'Best parameters: {gs_lr_3.best_params_}')\n",
    "lr_3 = gs_lr_3.best_estimator_\n",
    "print(f'Test score: {lr_3.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8696451451172637"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, lr_3.predict(X_test_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of predicted sale test set: 101\n",
      "Count of predicted sale train set: 340\n",
      "Count of actual sales test set: 29\n"
     ]
    }
   ],
   "source": [
    "print(f'Count of predicted sale test set: {sum(lr_3.predict(X_test_sc))}')\n",
    "\n",
    "print(f'Count of predicted sale train set: {sum(lr_3.predict(X_train_sc))}')\n",
    "\n",
    "print(f'Count of actual sales test set: {sum(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred full price</th>\n",
       "      <th>pred sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual full price</th>\n",
       "      <td>543</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual sale</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pred full price  pred sale\n",
       "actual full price              543         76\n",
       "actual sale                      4         25"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, lr_3.predict(X_test_sc))\n",
    "\n",
    "cm_df = pd.DataFrame(cm, columns = ['pred full price', 'pred sale'],\n",
    "            index = ['actual full price', 'actual sale'])\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8852988691437803"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specificity \n",
    "(cm_df.iloc[0,0])/(cm_df.iloc[0,1]+cm_df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8620689655172413"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sensitivity \n",
    "(cm_df.iloc[1,1]/(cm_df.iloc[1,0]+cm_df.iloc[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training score for gs: 0.8759011328527292\n",
      "Best parameters: {'C': 1, 'class_weight': 'balanced', 'max_iter': 3000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Test score: 0.9552469135802469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_3 = LogisticRegression()\n",
    "gs_lr_3 = GridSearchCV(\n",
    "            estimator = lr_3, \n",
    "            param_grid = {\n",
    "                 'penalty': ['l1','l2'],\n",
    "                 'C': [.75, 1],\n",
    "                 'solver': ['saga'],\n",
    "                 'class_weight': ['balanced'],\n",
    "                'max_iter' : [3000,4000,4500]},\n",
    "            cv = 2,\n",
    "            scoring = 'accuracy',\n",
    "            refit = 'roc_auc')\n",
    "\n",
    "gs_lr_3.fit(X_train_sc, y_train)\n",
    "print(f'Best training score for gs: {gs_lr_3.best_score_}')\n",
    "print(f'Best parameters: {gs_lr_3.best_params_}')\n",
    "lr_3 = gs_lr_3.best_estimator_\n",
    "print(f'Test score: {lr_3.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8712606540025625"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, lr_3.predict(X_test_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of predicted sale test set: 99\n",
      "Count of predicted sale train set: 339\n",
      "Count of actual sales test set: 29\n"
     ]
    }
   ],
   "source": [
    "print(f'Count of predicted sale test set: {sum(lr_3.predict(X_test_sc))}')\n",
    "\n",
    "print(f'Count of predicted sale train set: {sum(lr_3.predict(X_train_sc))}')\n",
    "\n",
    "print(f'Count of actual sales test set: {sum(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred full price</th>\n",
       "      <th>pred sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual full price</th>\n",
       "      <td>545</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual sale</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pred full price  pred sale\n",
       "actual full price              545         74\n",
       "actual sale                      4         25"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, lr_3.predict(X_test_sc))\n",
    "\n",
    "cm_df = pd.DataFrame(cm, columns = ['pred full price', 'pred sale'],\n",
    "            index = ['actual full price', 'actual sale'])\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training score for gs: 0.9521112255406797\n",
      "Best parameters: {'C': 1, 'class_weight': None, 'max_iter': 5000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Test score: 0.9552469135802469\n"
     ]
    }
   ],
   "source": [
    "lr_3 = LogisticRegression()\n",
    "gs_lr_3 = GridSearchCV(\n",
    "            estimator = lr_3, \n",
    "            param_grid = {\n",
    "                 'penalty': ['l1'],\n",
    "                 'C': [1],\n",
    "                 'solver': ['saga'],\n",
    "                 'class_weight': [None,'balanced'],\n",
    "                'max_iter' : [5000, 5500]},\n",
    "            cv = 2,\n",
    "            scoring = 'accuracy',\n",
    "            refit = 'roc_auc')\n",
    "\n",
    "gs_lr_3.fit(X_train_sc, y_train)\n",
    "print(f'Best training score for gs: {gs_lr_3.best_score_}')\n",
    "print(f'Best parameters: {gs_lr_3.best_params_}')\n",
    "lr_3 = gs_lr_3.best_estimator_\n",
    "print(f'Test score: {lr_3.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6166508829591667"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, lr_3.predict(X_test_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of predicted sale test set: 12\n",
      "Count of predicted sale train set: 28\n",
      "Count of actual sales test set: 29\n"
     ]
    }
   ],
   "source": [
    "print(f'Count of predicted sale test set: {sum(lr_3.predict(X_test_sc))}')\n",
    "\n",
    "print(f'Count of predicted sale train set: {sum(lr_3.predict(X_train_sc))}')\n",
    "\n",
    "print(f'Count of actual sales test set: {sum(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred full price</th>\n",
       "      <th>pred sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual full price</th>\n",
       "      <td>614</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual sale</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pred full price  pred sale\n",
       "actual full price              614          5\n",
       "actual sale                     22          7"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, lr_3.predict(X_test_sc))\n",
    "\n",
    "cm_df = pd.DataFrame(cm, columns = ['pred full price', 'pred sale'],\n",
    "            index = ['actual full price', 'actual sale'])\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.8796296296296297\n"
     ]
    }
   ],
   "source": [
    "lr_3 = LogisticRegression()\n",
    "gs_lr_3 = GridSearchCV(\n",
    "            estimator = lr_3, \n",
    "            param_grid = {\n",
    "                 'penalty': ['l1'],\n",
    "                 'C': [1],\n",
    "                 'solver': ['saga'],\n",
    "                 'class_weight': ['balanced'],\n",
    "                'max_iter' : [5000, 5500]},\n",
    "            cv = 2,\n",
    "            scoring = 'precision',\n",
    "            refit = 'roc_auc')\n",
    "\n",
    "gs_lr_3.fit(X_train_sc, y_train)\n",
    "print(f'Best training score for gs: {gs_lr_3.best_score_}')\n",
    "print(f'Best parameters: {gs_lr_3.best_params_}')\n",
    "lr_3 = gs_lr_3.best_estimator_\n",
    "print(f'Test score: {lr_3.score(X_test_sc, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8712606540025625"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, lr_3.predict(X_test_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of predicted sale test set: 99\n",
      "Count of predicted sale train set: 337\n",
      "Count of actual sales test set: 29\n"
     ]
    }
   ],
   "source": [
    "print(f'Count of predicted sale test set: {sum(lr_3.predict(X_test_sc))}')\n",
    "\n",
    "print(f'Count of predicted sale train set: {sum(lr_3.predict(X_train_sc))}')\n",
    "\n",
    "print(f'Count of actual sales test set: {sum(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred full price</th>\n",
       "      <th>pred sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual full price</th>\n",
       "      <td>545</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual sale</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pred full price  pred sale\n",
       "actual full price              545         74\n",
       "actual sale                      4         25"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, lr_3.predict(X_test_sc))\n",
    "\n",
    "cm_df = pd.DataFrame(cm, columns = ['pred full price', 'pred sale'],\n",
    "            index = ['actual full price', 'actual sale'])\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
